# L-layer Neural Network 

As I learned the critical functions such as forward propagation, backward propagation, how to initialize parameters, grads, and other functions, I am currently learning how to apply them to a L-neural network. What is a L-layer neural network? 

### Deep Learning Architecture 

<img width="800" alt="{2F6A3B3B-834A-4676-9505-E8FF73287424}" src="https://github.com/user-attachments/assets/65e60bce-db64-4020-a09e-34bc4fff1bf2" />

This is an example of a L-layer neural network I learned from Andrew NG (Deep Learning - Specialized via Coursea). This comes with L layers of computations between the input and output layers, and these layers include multiple hidden layers. I now know that the hidden layers do perform computations using activation functions from ReLU to tanh - depending on use cases - and also do weight matrices to learn complex representations of data. With the number of hidden layers, they all contribute to the depth of the network. 

