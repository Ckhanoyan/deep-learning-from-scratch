{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c468f4e",
   "metadata": {},
   "source": [
    "As I explore the book *Azure OpenAI Essentials: A Practical Guide to Unlocking Generative AI-Powered Innovation with Azure OpenAI*, I am using this Jupyter Notebook to document my learning process and demonstrate how these concepts can be applied to real-world healthcare scenarios.\n",
    "\n",
    "Suppose I am tasked with creating an enterprise document question-answer solution for a healthcare insurance provider. The solution should leverage all healthcare documents and medical history provided by the insurer to enable members to interact with a chatbot. Members can ask the chatbot questions related to their insurance policies, such as coverage details, claim status, or benefits, and receive accurate and context-aware responses. This solution will utilize Azure OpenAI for generating embeddings and answering prompts, along with Azure Cognitive Search for retrieving the most relevant documents.\n",
    "\n",
    "**Note**: This task is solely for my personal practice and learning purposes. It is not related to my current job, nor is it intended as advice or a production-ready solution for others to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c1e23",
   "metadata": {},
   "source": [
    "### Objective\n",
    "The objective of this notebook is to build an enterprise document question-answer solution for a healthcare insurance provider. This solution will:\n",
    "1. Leverage Azure OpenAI to generate embeddings and answer user queries.\n",
    "2. Use Azure Cognitive Search to retrieve the most relevant healthcare documents based on user queries.\n",
    "3. Provide accurate and context-aware responses to users' questions about their insurance policies.\n",
    "\n",
    "### Workflow\n",
    "This notebook will follow these steps:\n",
    "1. **Import Required Packages**: Load all necessary libraries and dependencies.\n",
    "2. **Set Up Environment Variables**: Configure Azure OpenAI and Azure Cognitive Search credentials.\n",
    "3. **Initialize Services**: Connect to Azure OpenAI and Azure Cognitive Search.\n",
    "4. **Define Helper Functions**: Implement functions for document retrieval, embedding generation, and answering queries.\n",
    "5. **Run the Solution**: Demonstrate the end-to-end process by answering sample user queries.\n",
    "\n",
    "### Prerequisites\n",
    "Before running this notebook, ensure the following:\n",
    "1. **Azure OpenAI Deployment**:\n",
    "   - You have access to an Azure OpenAI deployment. Please note that access to Azure OpenAI models requires you to be either an enterprise customer or partner with a company email address.\n",
    "   - Deployed models include GPT-4 or GPT-3.5, configured to handle user queries effectively.\n",
    "\n",
    "2. **Prompt Engineering**:\n",
    "   - The system prompt for the Azure OpenAI model using GPT-4 has been designed to act as an AI assistant that helps users find information related to their health insurance policies. This includes:\n",
    "     - Providing details about coverage, deductibles, and benefits.\n",
    "     - Answering questions about claim statuses and other policy-related queries.\n",
    "   - Example system prompt I set up for this task:\n",
    "     ```\n",
    "     {\"role\": \"system\", \"content\": \"You are an AI assistant that specializes in helping users find information about their health insurance policies. You provide accurate, concise, and context-aware answers based on the user's query and the provided document context.\"}\n",
    "     ```\n",
    "      ```\n",
    "     {\"role\": \"user\", \"content\": \"Will my health insurance cover hearing aids for my son?\"}\n",
    "     ```\n",
    "      ```\n",
    "     {\"role\": \"assistant\", \"content\": \"Yes, your health insurance will cover hearing aids for your son. However, you may need to pay a $100 copay as part of your plan's coverage policy.\"}\n",
    "     ```\n",
    "\n",
    "3. **Azure Cognitive Search Index**:\n",
    "   - The Azure Cognitive Search index is populated with healthcare documents, insurance policies, and other relevant data.\n",
    "   - The index includes an embedding field for vector search to enable semantic retrieval of the most relevant documents.\n",
    "   - The index name for this task I created is: `azureblob-healthcare-index`.\n",
    "\n",
    "4. **Environment Variables**:\n",
    "   - Ensure the following environment variables are set up in a `.env` file:\n",
    "      - `AZURE_OPENAI_ENDPOINT`\n",
    "      - `AZURE_OPENAI_API_KEY`\n",
    "      - `AZURE_OPENAI_DEPLOYMENT`\n",
    "      - `AZURE_SEARCH_ENDPOINT`\n",
    "      - `AZURE_SEARCH_API_KEY`\n",
    "      - `AZURE_SEARCH_INDEX_NAME`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08560dff",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# ASCII diagram: How User asks a question and gets an answer from Azure OpenAI\n",
    "print(\"\"\"\n",
    "+------------------+       Question            +------------------+\n",
    "|                  | ------------------------> |                  |\n",
    "|      User        |                           |   Azure OpenAI   |\n",
    "|                  |                           |   Embeddings     |\n",
    "+------------------+                           +------------------+\n",
    "          ^                                           |\n",
    "          |                                           v\n",
    "          |                                 +----------------------+\n",
    "          |                                 |   Vector Database    |\n",
    "          |                                 | (Azure OpenAI Embeds)| <------ Where it contains an index with <azureblob-healthcare> docs\n",
    "          |                                 +----------------------+\n",
    "          |                                           |--------------------- Top k \n",
    "          |                                           v\n",
    "          |                                 +----------------------+\n",
    "          |                                 |  Azure OpenAI Answer |\n",
    "          |                                 |       Prompt         |\n",
    "          |                                 +----------------------+\n",
    "          |                                           |\n",
    "          |                                           v\n",
    "          |                Answer              +------------------+\n",
    "          -----------------------------------  |                  |\n",
    "                                               |   Azure OpenAI   |\n",
    "                                               |   Answering      |\n",
    "                                               +------------------+\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b2af83",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Import Packages\n",
    "\n",
    "This markdown section provides a clear overview of the notebook's purpose, workflow, and prerequisites, making it easier for myself to understand and follow along. Once I've added this, I can proceed with the Python section to import the required packages.\n",
    "\n",
    "**Note** that I have also explored their official GitHub repository for code samples to aid my learning process and implementation here. The link is here: https://github.com/PacktPublishing/Azure-OpenAI-Essentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages required for this healthcare-document task\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from langchain import OpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.retrievers import AzureCognitiveSearchRetriever\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import AzureSearch\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211007b5",
   "metadata": {},
   "source": [
    "### Step 2: Load Environment Variables and Initialize Azure\n",
    "\n",
    "In this step, we will load the environment variables required to configure Azure OpenAI and Azure Cognitive Search services. These variables include API keys, endpoints, and deployment names, which are essential for securely connecting to the Azure services.\n",
    "\n",
    "**Why is this important?**\n",
    "For this healthcare task, environment variables ensure that sensitive information, such as API keys and endpoints, is not hardcoded into the script. This approach enhances security and allows for easier configuration changes without modifying the code. Properly loading these variables is critical for accessing the healthcare documents and generating accurate responses using Azure OpenAI and Azure Cognitive Search.\n",
    "\n",
    "**Initialize Azure OpenAI**:\n",
    "\n",
    "Azure OpenAI is used to generate embeddings for semantic search and to answer user queries. Initializing Azure OpenAI ensures that the script can connect to the correct deployment and use the appropriate model for generating embeddings and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-env",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Azure OpenAI environment variables\n",
    "OPENAI_API_TYPE = \"azure\"  # Specify that you are using Azure OpenAI\n",
    "OPENAI_API_BASE = os.getenv(\"OPENAI_API_BASE\", \"https://your-azure-openai-endpoint\")  # Replace with your endpoint\n",
    "OPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\", \"2023-03-15-preview\")  # Default API version\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your-azure-openai-api-key\")  # Replace with your API key\n",
    "\n",
    "# Deployment-specific variables for Azure OpenAI\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\", \"your-deployment-name\")  # Replace with your deployment name (e.g., gpt-4 or gpt-35-turbo)\n",
    "OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_EMBEDDING_DEPLOYMENT_NAME\", \"text-embedding-ada-002\")  # Replace with your embedding deployment name\n",
    "\n",
    "# Initialize Azure OpenAI\n",
    "openai.api_type = OPENAI_API_TYPE\n",
    "openai.api_base = OPENAI_API_BASE\n",
    "openai.api_version = OPENAI_API_VERSION\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Print a message to confirm initialization (for learning purposes)\n",
    "print(\"Azure OpenAI environment variables loaded and initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa74f0e",
   "metadata": {},
   "source": [
    "**Initialize Azure Cognitive Search**:\n",
    "\n",
    "Azure Cognitive Search is used to retrieve the most relevant documents based on the user's query. Initializing this service allows the script to connect to the search index, perform vector-based searches, and retrieve documents that will be used as context for answering user queries. The values provided in the code are **samples only** and should be replaced with actual endpoint, API key, and index name when connecting to a real Azure Cognitive Search service.\n",
    "\n",
    "These steps are critical for securely and effectively connecting to the Azure services required for this healthcare document question-answer solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure Cognitive Search with SAMPLE values for learning purposes\n",
    "VECTOR_STORE_ADDRESS = \"https://my-cognitive-search-service.search.windows.net\"\n",
    "VECTOR_STORE_PASSWORD = \"1234567890abcdef1234567890abcdef\"\n",
    "AZURE_COGNITIVE_SEARCH_INDEX_NAME = \"azureblob-healthcare-index\"\n",
    "AZURE_COGNITIVE_SERVICE_NAME = \"my-cognitive-search-service\"\n",
    "AZURE_COGNITIVE_SEARCH_API = \"2021-04-30-Preview\"\n",
    "\n",
    "# Print the configuration for confirmation (for learning purposes)\n",
    "print(\"Azure Cognitive Search initialized with the following configuration:\")\n",
    "print(f\"Endpoint: {VECTOR_STORE_ADDRESS}\")\n",
    "print(f\"Index Name: {AZURE_COGNITIVE_SEARCH_INDEX_NAME}\")\n",
    "print(f\"Service Name: {AZURE_COGNITIVE_SERVICE_NAME}\")\n",
    "print(f\"API Version: {AZURE_COGNITIVE_SEARCH_API}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60171948",
   "metadata": {},
   "source": [
    "### Step 3: Test Connectivity\n",
    "\n",
    "**Why Test Connectivity with Azure OpenAI?**\n",
    "\n",
    "Testing connectivity with Azure OpenAI ensures that the environment variables, API keys, and deployment configurations are correctly set up and functional. This step is crucial to verify that the application can successfully communicate with the Azure OpenAI service before proceeding with more complex operations, such as generating embeddings or answering queries. By identifying and resolving connectivity issues early, we can save time and avoid potential errors during the implementation of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using model engine for testing the connectivity OpenAI\n",
    "llm = AzureOpenAI(engine=OPENAI_DEPLOYMENT_NAME, temperature=0) # Initialize the Azure OpenAI model engine\n",
    "print(llm('Hello, tell me about yourself.')) # Test the model engine with a sample input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7176ad",
   "metadata": {},
   "source": [
    "**Example Output**:\n",
    "Based on the system setup, the response may look like this:\n",
    "\n",
    "**Response**: I am an AI assistant designed to help users with questions related to their healthcare and insurance policies. I can provide information about coverage, deductibles, claims, and other policy-related details. How can I assist you today?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871adbf3",
   "metadata": {},
   "source": [
    "**OPTIONAL** (Cell 14): The code sample below is an OPTIONAL step to test the end-to-end workflow.\n",
    "\n",
    "This step demonstrates how to simulate the process of retrieving relevant documents (e.g., health insurance policies) and generating an answer using Azure OpenAI. It assumes that:\n",
    "1. Relevant documents are retrieved from Azure Cognitive Search (or simulated for learning purposes).\n",
    "2. The documents are combined into a context to guide Azure OpenAI in answering the user's query.\n",
    "3. Azure OpenAI generates a response based on the provided context and query.\n",
    "\n",
    "**Note**: This step assumes that the simple connectivity test using `llm` in **Cell 11** has already been successfully established. Ensure that the `llm` object is properly initialized before running this step.\n",
    "\n",
    "This is a useful step to validate the integration of document retrieval and answer generation in a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf69a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Test the end-to-end workflow with a sample query\n",
    "\n",
    "# Define a sample query\n",
    "query = \"What is my current deductible for health insurance?\"\n",
    "\n",
    "# Step 1: Retrieve relevant documents using Azure Cognitive Search\n",
    "retrieved_docs = [\n",
    "    \"Your current deductible is $500 for individual coverage.\",\n",
    "    \"For family coverage, the deductible is $1,000.\",\n",
    "    \"Please refer to your policy document for more details.\"\n",
    "]  # Simulated results for learning purposes\n",
    "\n",
    "# Step 2: Combine retrieved documents into a context for the prompt\n",
    "context = \"\\n\".join(retrieved_docs)\n",
    "prompt = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "# Step 3: Use Azure OpenAI to generate an answer\n",
    "try:\n",
    "    response = llm(prompt)  # Assuming `llm` is already initialized in Cell 11\n",
    "    print(\"Generated Answer:\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(\"Error generating answer:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa65b4",
   "metadata": {},
   "source": [
    "**Example Output**:\n",
    "Based on the provided context, the response may look like this:\n",
    "\n",
    "**Answer**: Your current deductible is **$500** for individual coverage. For family coverage, the deductible is **$1,000**. If you need more details, please refer to your policy document or contact your insurance provider directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc28840",
   "metadata": {},
   "source": [
    "### Step 4: Load Healthcare Documents\n",
    "\n",
    "In this step, we will load healthcare-related documents, such as insurance policies, claims history, and medical records, from PDF files. These documents will be processed and added to the vector search index to enable semantic search and retrieval. \n",
    "\n",
    "**Why is this important?**\n",
    "Loading and indexing these documents is a critical step in building the question-answer solution. By converting the content of these documents into embeddings and storing them in the vector search index, we enable the system to retrieve the most relevant documents based on user queries. This ensures that the AI assistant can provide accurate and context-aware responses.\n",
    "\n",
    "**Steps**:\n",
    "1. Read the content of PDF files.\n",
    "2. Generate embeddings for the document content.\n",
    "3. Add the documents and their embeddings to the vector search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fde45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the directory containing healthcare documents\n",
    "directory_path = \"path/to/healthcare/documents\"  # Replace with the path to your healthcare documents\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(directory_path):\n",
    "    print(f\"Error: The directory '{directory_path}' does not exist.\")\n",
    "else: \n",
    "    # Load the healthcare documents from the directory\n",
    "    loader = DirectoryLoader(\"path/to/healthcare/documents\", glob=\"*.pdf\") # Load only PDF files (you can adjust for specific file types)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Print the number of documents loaded\n",
    "    print(f\"Loaded {len(documents)} healthcare documents.\")\n",
    "\n",
    "    # OPTIONALLY: Print the content of the first document for verification\n",
    "    if documents:\n",
    "        print(\"\\nPreview of the first healthcare document:\")\n",
    "        print(documents[0][:500])  # Print the first 500 characters of the first document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3531f58",
   "metadata": {},
   "source": [
    "### Step 5: Split Healthcare Documents into Chunks\n",
    "\n",
    "After loading the healthcare documents, the next step is to split them into smaller chunks. This is important because:\n",
    "\n",
    "1. Generating embeddings for smaller chunks of text ensures that the embeddings capture the semantic meaning of specific sections of the document, rather than the entire document.\n",
    "2. Splitting healthcare documents into chunks allows the vector search to retrieve the most relevant sections of a document, rather than the entire document, improving the accuracy of the results.\n",
    "3. Large healthcare documents may exceed the token limits of the embedding model or the OpenAI model. Splitting them into smaller chunks ensures compatibility with these limits.\n",
    "\n",
    "The following code demonstrates how to split the loaded documents into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da30f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Maximum number of characters in each chunk\n",
    "    chunk_overlap=200  # Overlap between chunks to maintain context\n",
    ")\n",
    "\n",
    "# Split the loaded healthcare documents into chunks\n",
    "if documents:\n",
    "    document_chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split the documents into {len(document_chunks)} chunks.\")\n",
    "\n",
    "    # Optionally, preview the first chunk\n",
    "    print(\"\\nPreview of the first chunk:\")\n",
    "    print(document_chunks[0])\n",
    "else:\n",
    "    print(\"No documents loaded to split.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19d3c1f",
   "metadata": {},
   "source": [
    "This step above (cell 19) splits the loaded healthcare documents into smaller chunks using a text splitter. Each chunk is limited to 1,000 characters with a 200-character overlap to maintain context between chunks. Splitting healthcare documents ensures efficient embedding generation, preserves semantic meaning, and improves the accuracy of vector-based searches by focusing on specific sections of the documents.\n",
    "\n",
    "These values (chunk size and overlap) can be adjusted depending on the size and structure of the documents to better suit specific use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e764cd",
   "metadata": {},
   "source": [
    "### Step 6: Initialize Vector Store and Add Healthcare Document Chunks\n",
    "\n",
    "In this step, we initialize the vector store using Azure Cognitive Search and add the healthcare document chunks to it. This process involves:\n",
    "1. Initializing the embedding model to generate vector representations of the document chunks.\n",
    "2. Configuring the vector store to use Azure Cognitive Search as the backend.\n",
    "3. Adding the document chunks to the vector store for efficient vector-based searches.\n",
    "\n",
    "This step ensures that the document chunks are stored in a searchable format, enabling semantic search capabilities for user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embedding model\n",
    "deployment_model = \"text-embedding-ada-002\"  # Sample (Replace with your actual embedding deployment name)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    deployment=deployment_model,\n",
    "    chunk_size=1,  # Process one document at a time\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_base=OPENAI_API_BASE,\n",
    "    openai_api_type=OPENAI_API_TYPE,\n",
    "    openai_api_version=OPENAI_API_VERSION,\n",
    ")\n",
    "\n",
    "# Initialize the vector store\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=VECTOR_STORE_ADDRESS,\n",
    "    azure_search_key=VECTOR_STORE_PASSWORD,\n",
    "    index_name=\"azureblob-healthcare-index\",  # Sample that I created earlier\n",
    "    embedding_function=embeddings.embed_documents,  # Use embed_documents for adding documents\n",
    ")\n",
    "\n",
    "# Add document chunks to the vector store\n",
    "if document_chunks:\n",
    "    list_of_docs = vector_store.add_documents(documents=document_chunks)\n",
    "    print(f\"Successfully added {len(document_chunks)} document chunks to the vector store.\")\n",
    "else:\n",
    "    print(\"No document chunks available to add to the vector store.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182fd28",
   "metadata": {},
   "source": [
    "**Summary**: From Loading Documents to Adding Chunks to Vector Search\n",
    "\n",
    "1. Loading Healthcare Documents:\n",
    "   - Healthcare documents are loaded from a specified directory using `DirectoryLoader`, which reads files in supported formats (e.g., PDFs).\n",
    "\n",
    "2. Splitting Documents into Chunks:\n",
    "   - The loaded documents are split into smaller, manageable chunks using `RecursiveCharacterTextSplitter`. Each chunk is limited to 1,000 characters with a 200-character overlap to maintain context and improve search accuracy.\n",
    "\n",
    "3. Initializing the Embedding Model:\n",
    "   - An embedding model, such as `text-embedding-ada-002`, is initialized to generate vector representations of the document chunks. These embeddings capture the semantic meaning of the text.\n",
    "\n",
    "4. Adding Chunks to the Vector Store:\n",
    "   - The document chunks are added to a vector store, such as Azure Cognitive Search, which enables efficient semantic search. This allows the system to retrieve the most relevant sections of the documents based on user queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a59678f",
   "metadata": {},
   "source": [
    "### Step 7: Perform a Similarity Search\n",
    "\n",
    "In this step, we perform a similarity search to retrieve the top similar healthcare documents that are most relevant to a user's query. This involves comparing the user's query embedding with the embeddings of the document chunks stored in the vector store.\n",
    "\n",
    "1. Similarity search allows the system to quickly identify and retrieve the most relevant sections of healthcare documents, saving time and improving user experience.\n",
    "\n",
    "2. By retrieving the top 3 most similar documents, the system can provide accurate and context-aware answers to user queries.\n",
    "\n",
    "3. Focusing on the most relevant documents ensures that the system generates responses based on the most pertinent information, reducing the likelihood of irrelevant or incorrect answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea74eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search to retrieve the top 3 most relevant healthcare documents\n",
    "query = \"Will my health insurance cover hearing aids for my child?\"  # Example user query\n",
    "\n",
    "# Perform the similarity search\n",
    "try:\n",
    "    # Retrieve the top 3 most similar documents\n",
    "    top_k = 3\n",
    "    similar_documents = vector_store.similarity_search(query, k=top_k)\n",
    "    search_type = \"similarity\"  # Specify the type of search (e.g., \"similarity\" or \"semantic\")\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Top {top_k} most similar documents for the query: '{query}'\\n\")\n",
    "    for i, doc in enumerate(similar_documents, start=1):\n",
    "        print(f\"Document {i}:\")\n",
    "        print(doc.page_content)  # Assuming `page_content` contains the text of the document\n",
    "        print(\"-\" * 50)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the similarity search: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b24d5",
   "metadata": {},
   "source": [
    "**Example Output**:\n",
    "Based on the similarity search, the system may retrieve the following response:\n",
    "\n",
    "**Answer**: Yes, your health insurance will cover hearing aids for your child. However, you may need to copay $100 as part of your plan's coverage policy.\n",
    "\n",
    "The response is supported by the following similar documents retrieved from the vector store:\n",
    "1. **Document 1**: \"Hearing aids are covered under your health insurance plan with a $100 copay for each device.\"\n",
    "2. **Document 2**: \"Your health insurance policy includes coverage for hearing aids for dependents under the age of 18.\"\n",
    "3. **Document 3**: \"Please refer to Section 5 of your policy document for details on hearing aid coverage and associated costs.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712c93a",
   "metadata": {},
   "source": [
    "### Step 8: Create a Question-Answering (QA) System Using RetrievalQA\n",
    "\n",
    "In this step, we initialize a question-answering (QA) system using the `RetrievalQA` chain from `langchain`. This chain combines the power of Azure OpenAI for generating answers with the vector store for retrieving relevant healthcare documents. \n",
    "\n",
    "The QA system works as follows:\n",
    "1. A user query is passed to the chain.\n",
    "2. The chain retrieves the most relevant documents from the vector store using similarity search.\n",
    "3. Azure OpenAI generates a context-aware answer based on the retrieved documents.\n",
    "\n",
    "This step enables the system to provide accurate and contextually relevant answers to user queries about healthcare and insurance policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RetrievalQA chain\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=AzureOpenAI(\n",
    "        deployment_name=OPENAI_DEPLOYMENT_NAME,  # Replace with your Azure OpenAI deployment name\n",
    "        model=OPENAI_DEPLOYMENT_NAME,  # Use the same model for the LLM\n",
    "        temperature=0  # OPTIONAL: Set temperature to 0 for deterministic answers\n",
    "    ),\n",
    "    chain_type=\"stuff\",  # Concatenates all retrieved documents into a single string\n",
    "    retriever=vector_search.as_retriever(),  # Use the vector store as the retriever\n",
    "    return_source_documents=True  # Include source documents in the output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7453229",
   "metadata": {},
   "source": [
    "#### Explanation of `chain_type` and `temperature`\n",
    "\n",
    "The `chain_type` parameter determines how retrieved documents are processed before being passed to the LLM. Common options include `stuff` (concatenates all documents into a single string), `map_reduce` (processes documents individually and combines results), and `refine` (iteratively refines the answer using additional documents). For small datasets, `stuff` is efficient, while `map_reduce` or `refine` are better for handling larger datasets or ensuring context-aware answers.\n",
    "\n",
    "The `temperature` parameter controls the randomness of the model's output, ranging from `0` (deterministic and consistent answers) to `1` (creative and diverse responses). For this healthcare use case, setting `temperature=0` is recommended to ensure accurate and reliable answers. **If you have not set the temperature in your own GPT model deployment**, adding the `temperature` parameter in this cell is optional. For more details, refer to the [LangChain Documentation](https://langchain.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d641c",
   "metadata": {},
   "source": [
    "### Step 9: Test the QA System with a Query\n",
    "\n",
    "In this step, we test the QA system by providing a sample query, such as \"Will my health insurance cover hearing aids for my child?\". The system retrieves relevant healthcare documents and insurance policies from the vector store and generates an accurate, context-aware answer based on the retrieved information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6662e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Will my health insurance cover hearing aids for my child?\"\n",
    "\n",
    "try:\n",
    "    result = chain({\"query\": query})  # Use chain() to get both the answer and source documents\n",
    "\n",
    "    # Print the generated answer\n",
    "    print(\"Answer:\")\n",
    "    print(result['result'])  # The generated answer\n",
    "\n",
    "    # Print the source documents\n",
    "    print(\"\\nSource Documents:\")\n",
    "    if 'source_documents' in result and result['source_documents']:\n",
    "        for i, doc in enumerate(result['source_documents'], start=1):\n",
    "            print(f\"Document {i}: {doc.page_content}\")\n",
    "    else:\n",
    "        print(\"No source documents were retrieved.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the query: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd3ad3",
   "metadata": {},
   "source": [
    "### Summary of the Healthcare Document Question-Answering System\n",
    "\n",
    "This end-to-end solution demonstrates how to build a healthcare document question-answering system using Azure OpenAI and Azure Cognitive Search. The process begins by loading healthcare documents with `DirectoryLoader` and splitting them into smaller chunks using `RecursiveCharacterTextSplitter` to ensure efficient embedding generation and semantic accuracy. These chunks are embedded using an Azure OpenAI embedding model and stored in a vector store powered by Azure Cognitive Search, enabling semantic search capabilities. A similarity search retrieves the most relevant documents for a user query, and a `RetrievalQA` chain is created using Azure OpenAI to generate accurate, context-aware answers based on the retrieved documents. This solution effectively integrates document retrieval, embeddings, and language models to address real-world healthcare use cases.\n",
    "\n",
    "**Note**: This project is part of my learning process and is not intended for production use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
