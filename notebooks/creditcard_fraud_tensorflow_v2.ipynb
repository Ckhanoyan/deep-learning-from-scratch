{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db08e1d",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection â€” TensorFlow Baseline\n",
    "**Purpose:** Train a simple neural network to detect fraud using the full dataset (~250k rows).  \n",
    "We will handle imbalance using class weighting and evaluate with PR AUC and ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da08e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow and imbalanced-learn (if not already installed)\n",
    "%pip install -q tensorflow imbalanced-learn\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39cff18",
   "metadata": {},
   "source": [
    "We import standard libraries for data handling and visualization, \n",
    "plus TensorFlow/Keras for building our neural network. \n",
    "`roc_auc_score` and `average_precision_score` will help evaluate the model on imbalanced data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35609d92-92e9-4fce-98e6-c913b7a55cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (284807, 31)\n",
      "Class distribution:\n",
      " Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from S3\n",
    "bucket = \"myfraudcreditcardbucket\"\n",
    "file_name = \"creditcard.csv\"\n",
    "s3_path = f\"s3://{bucket}/{file_name}\"\n",
    "\n",
    "df = pd.read_csv(s3_path)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Class distribution:\\n\", df[\"Class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57df1cf-f3f9-4534-886c-77610bdeafff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(s3_path)\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (assumes CSV is in the same folder)\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "df.shape, df['Class'].value_counts(), df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1586c",
   "metadata": {},
   "source": [
    "We load the CSV and check: \n",
    "- number of rows and columns\n",
    "- class counts\n",
    "- fraction of fraud (Class=1) vs legit (Class=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e011b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview first few rows\n",
    "display(df.head())\n",
    "\n",
    "# Class distribution plot\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.barplot(x=df['Class'].value_counts().index, y=df['Class'].value_counts().values)\n",
    "plt.xticks([0,1], ['Legit (0)', 'Fraud (1)'])\n",
    "plt.title('Class counts'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba21bec",
   "metadata": {},
   "source": [
    "We visually confirm the extreme imbalance: fraud is a tiny fraction (~0.17%). \n",
    "This is why metrics like PR AUC and recall are more important than accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7806208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features & target\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Split data (stratified to preserve class ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d7dbb",
   "metadata": {},
   "source": [
    "We split 80/20 for training/testing, \n",
    "using `stratify=y` to preserve the extremely rare fraud class ratio in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa878fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only scale 'Amount' and 'Time'; V1â€“V28 are already PCA-transformed\n",
    "scaler = StandardScaler()\n",
    "X_train[['Time', 'Amount']] = scaler.fit_transform(X_train[['Time', 'Amount']])\n",
    "X_test[['Time', 'Amount']] = scaler.transform(X_test[['Time', 'Amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0923f8d4",
   "metadata": {},
   "source": [
    "Neural networks perform better when numeric features are roughly on the same scale. \n",
    "We scale only 'Time' and 'Amount' because V1â€“V28 are already PCA components (roughly normalized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6fd0da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                992       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1537 (6.00 KB)\n",
      "Trainable params: 1537 (6.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 10:12:51.579362: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Simple fully connected network\n",
    "model = Sequential([\n",
    "    Dense(32, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # binary output\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.AUC(name='auc')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89850346",
   "metadata": {},
   "source": [
    "(The CUDA error above just means TensorFlow didnâ€™t find a GPU on my environment (likely running CPU-only), and my model will still run but just slower a bit so I will ignore this.)\n",
    "\n",
    "In this step, we design a simple feed-forward neural network for our credit card fraud detection task. Here's why we made each choice:\n",
    "\n",
    "- **Dense layers with ReLU activation (`relu`)**:  \n",
    "  ReLU (Rectified Linear Unit) is the most common activation function for hidden layers because it helps the network learn complex, non-linear patterns while avoiding problems like vanishing gradients that occur with older functions (e.g., sigmoid, tanh). ReLU keeps training efficient and effective.  \n",
    "\n",
    "- **Output layer with sigmoid activation**:  \n",
    "  Since this is a binary classification problem (fraud vs. non-fraud), we use `sigmoid` to output probabilities between 0 and 1.  \n",
    "\n",
    "- **Loss function (`binary_crossentropy`)**:  \n",
    "  This is the standard loss for binary classification. It measures the difference between predicted probabilities and actual labels (fraud = 1, not fraud = 0). Minimizing this loss helps the model improve its probability predictions.  \n",
    "\n",
    "- **Optimizer (Adam, learning rate = 0.001)**:  \n",
    "  Adam is widely used because it adapts the learning rate for each parameter automatically, combining the strengths of momentum and RMSprop optimizers. The default learning rate of **0.001** is a good starting pointâ€”itâ€™s small enough to ensure stable convergence but fast enough to make progress during training. If training is too slow or unstable, this value can be tuned.  \n",
    "\n",
    "- **Metrics (`accuracy`, `AUC`, `Precision`, `Recall`)**:  \n",
    "  - `accuracy` gives the overall correctness, but can be misleading with imbalanced datasets.  \n",
    "  - `AUC` (Area Under ROC Curve) measures the modelâ€™s ability to distinguish between fraud and non-fraud across thresholds.  \n",
    "  - `precision` tells us how many of the transactions predicted as fraud are truly fraud.  \n",
    "  - `recall` tells us how many of the actual frauds were correctly detected.  \n",
    "  These metrics provide a balanced view of performance beyond just accuracy, which is critical in fraud detection where fraud cases are rare.  \n",
    "\n",
    "  We also create a small dense network:\n",
    "- 32 â†’ 16 neurons in hidden layers\n",
    "- Dropout 20% to reduce overfitting\n",
    "- Sigmoid output for binary classification\n",
    "- Use AUC as a metric for evaluation during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c3982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.5008661206149896, 1: 289.14340101522845}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights: inverse of class frequency\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e5c86",
   "metadata": {},
   "source": [
    "So, the calculated class weights show that fraud cases (1) are very rare compared to non-fraud cases (0).  \n",
    "To balance this, each fraud sample is weighted about 289 times more than a non-fraud sample, ensuring the model pays more attention to detecting fraud. This helps prevent the model from always predicting \"not fraud\" due to class imbalance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fba7a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 10:19:32.720097: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 43746240 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "90/90 [==============================] - 16s 10ms/step - loss: 1.0366 - auc: 0.5612 - val_loss: 0.5611 - val_auc: 0.8860\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4473 - auc: 0.8593 - val_loss: 0.4230 - val_auc: 0.9284\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3478 - auc: 0.9178 - val_loss: 0.3073 - val_auc: 0.9480\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2813 - auc: 0.9391 - val_loss: 0.2313 - val_auc: 0.9571\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2553 - auc: 0.9538 - val_loss: 0.1963 - val_auc: 0.9684\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2287 - auc: 0.9600 - val_loss: 0.1687 - val_auc: 0.9742\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2034 - auc: 0.9676 - val_loss: 0.1537 - val_auc: 0.9787\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1691 - auc: 0.9787 - val_loss: 0.1272 - val_auc: 0.9796\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1718 - auc: 0.9773 - val_loss: 0.1202 - val_auc: 0.9807\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1703 - auc: 0.9802 - val_loss: 0.1154 - val_auc: 0.9818\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,          # start small; increase if needed\n",
    "    batch_size=2048,    # large batch works for big dataset\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025ca20",
   "metadata": {},
   "source": [
    "The model shows strong improvement across epochs. Validation AUC started at **0.8860** in epoch 1 and climbed to **0.9818** by epoch 10, indicating excellent ability to separate fraud from non-fraud. Meanwhile, the validation loss steadily decreased, suggesting the model is learning effectively without overfitting yet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e832a51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 2s 1ms/step\n",
      "PR AUC: 0.6865493065868986\n",
      "ROC AUC: 0.9785571445798353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9774    0.9885     56864\n",
      "           1     0.0649    0.9082    0.1211        98\n",
      "\n",
      "    accuracy                         0.9773     56962\n",
      "   macro avg     0.5324    0.9428    0.5548     56962\n",
      "weighted avg     0.9982    0.9773    0.9870     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities\n",
    "y_prob = model.predict(X_test).flatten()\n",
    "y_pred_05 = (y_prob > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "print(\"PR AUC:\", average_precision_score(y_test, y_prob))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(classification_report(y_test, y_pred_05, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46f1d3",
   "metadata": {},
   "source": [
    "The model achieved an excellent **ROC AUC of 0.9786**, showing very strong overall discrimination between fraud and non-fraud cases. The **PR AUC of 0.687** is also solid, which is more meaningful for this imbalanced dataset since it focuses on fraud detection. Precision for fraud (class 1) is relatively low (**0.0649**), but recall is very high (**0.9082**), meaning the model successfully captures most fraud cases while producing more false positives. This tradeoff is typical in fraud detection and can be tuned further by adjusting the decision threshold.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e0bfcc6-4dc1-4750-9219-03b2b0aa7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_default = (y_prob > 0.3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "271b6e0c-8982-4d6a-bfac-75e1462705e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     56864\n",
      "           1       0.03      0.92      0.05        98\n",
      "\n",
      "    accuracy                           0.94     56962\n",
      "   macro avg       0.51      0.93      0.51     56962\n",
      "weighted avg       1.00      0.94      0.97     56962\n",
      "\n",
      "ROC AUC: 0.9785571445798353\n",
      "PR AUC: 0.6865493065868986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
    "\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"PR AUC:\", average_precision_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3da695b1-dd1a-44b9-98e1-5af2f657b4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        y_true    y_prob  y_pred\n",
      "260549       0  0.020424       0\n",
      "207920       0  0.022005       0\n",
      "9890         0  0.111868       0\n",
      "169108       0  0.009085       0\n",
      "240991       0  0.134147       0\n",
      "216605       0  0.016075       0\n",
      "170739       0  0.057379       0\n",
      "146712       0  0.028239       0\n",
      "270298       0  0.108854       0\n",
      "91976        0  0.184660       0\n",
      "109053       0  0.135872       0\n",
      "120232       0  0.068312       0\n",
      "240679       0  0.088868       0\n",
      "197111       0  0.043105       0\n",
      "258617       0  0.039338       0\n",
      "115271       0  0.118311       0\n",
      "10697        0  0.106195       0\n",
      "149485       0  0.019753       0\n",
      "4763         0  0.082657       0\n",
      "2407         0  0.013978       0\n",
      "186654       0  0.046306       0\n",
      "44808        0  0.164087       0\n",
      "40938        0  0.010531       0\n",
      "252178       0  0.021987       0\n",
      "79255        0  0.014979       0\n",
      "134085       0  0.173714       0\n",
      "188613       0  0.018134       0\n",
      "5777         0  0.072969       0\n",
      "146436       0  0.015231       0\n",
      "201670       0  0.065001       0\n",
      "210731       0  0.036123       0\n",
      "222756       0  0.221859       0\n",
      "178998       0  0.208958       0\n",
      "137165       0  0.102386       0\n",
      "39705        0  0.020299       0\n",
      "75296        0  0.056591       0\n",
      "114404       0  0.021693       0\n",
      "160994       0  0.011119       0\n",
      "110489       0  0.065637       0\n",
      "222742       0  0.010603       0\n",
      "275470       0  0.038508       0\n",
      "230411       0  0.345839       1\n",
      "152066       0  0.016584       0\n",
      "69555        0  0.017807       0\n",
      "156307       0  0.013456       0\n",
      "283893       0  0.042482       0\n",
      "248470       0  0.123845       0\n",
      "102259       0  0.133780       0\n",
      "257381       0  0.078026       0\n",
      "43279        0  0.216784       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine predictions and probabilities for a few samples\n",
    "results = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'y_prob': y_prob,\n",
    "    'y_pred': y_pred_default\n",
    "})\n",
    "print(results.sample(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
