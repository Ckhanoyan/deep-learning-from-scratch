{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db08e1d",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection — TensorFlow Baseline\n",
    "**Purpose:** Train a simple neural network to detect fraud using the full dataset (~250k rows).  \n",
    "We will handle imbalance using class weighting and evaluate with PR AUC and ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da08e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow and imbalanced-learn (if not already installed)\n",
    "%pip install -q tensorflow imbalanced-learn\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39cff18",
   "metadata": {},
   "source": [
    "We import standard libraries for data handling and visualization, \n",
    "plus TensorFlow/Keras for building our neural network. \n",
    "`roc_auc_score` and `average_precision_score` will help evaluate the model on imbalanced data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35609d92-92e9-4fce-98e6-c913b7a55cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (284807, 31)\n",
      "Class distribution:\n",
      " Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from S3\n",
    "bucket = \"myfraudcreditcardbucket\"\n",
    "file_name = \"creditcard.csv\"\n",
    "s3_path = f\"s3://{bucket}/{file_name}\"\n",
    "\n",
    "df = pd.read_csv(s3_path)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Class distribution:\\n\", df[\"Class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57df1cf-f3f9-4534-886c-77610bdeafff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(s3_path)\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (assumes CSV is in the same folder)\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "df.shape, df['Class'].value_counts(), df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1586c",
   "metadata": {},
   "source": [
    "We load the CSV and check: \n",
    "- number of rows and columns\n",
    "- class counts\n",
    "- fraction of fraud (Class=1) vs legit (Class=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e011b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview first few rows\n",
    "display(df.head())\n",
    "\n",
    "# Class distribution plot\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.barplot(x=df['Class'].value_counts().index, y=df['Class'].value_counts().values)\n",
    "plt.xticks([0,1], ['Legit (0)', 'Fraud (1)'])\n",
    "plt.title('Class counts'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba21bec",
   "metadata": {},
   "source": [
    "We visually confirm the extreme imbalance: fraud is a tiny fraction (~0.17%). \n",
    "This is why metrics like PR AUC and recall are more important than accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7806208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features & target\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Split data (stratified to preserve class ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d7dbb",
   "metadata": {},
   "source": [
    "We split 80/20 for training/testing, \n",
    "using `stratify=y` to preserve the extremely rare fraud class ratio in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa878fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only scale 'Amount' and 'Time'; V1–V28 are already PCA-transformed\n",
    "scaler = StandardScaler()\n",
    "X_train[['Time', 'Amount']] = scaler.fit_transform(X_train[['Time', 'Amount']])\n",
    "X_test[['Time', 'Amount']] = scaler.transform(X_test[['Time', 'Amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0923f8d4",
   "metadata": {},
   "source": [
    "Neural networks perform better when numeric features are roughly on the same scale. \n",
    "We scale only 'Time' and 'Amount' because V1–V28 are already PCA components (roughly normalized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6fd0da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                992       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1537 (6.00 KB)\n",
      "Trainable params: 1537 (6.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 10:12:51.579362: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Simple fully connected network\n",
    "model = Sequential([\n",
    "    Dense(32, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # binary output\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.AUC(name='auc')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89850346",
   "metadata": {},
   "source": [
    "(The CUDA error above just means TensorFlow didn’t find a GPU on my environment (likely running CPU-only), and my model will still run but just slower a bit so I will ignore this.)\n",
    "\n",
    "In this step, we design a simple feed-forward neural network for our credit card fraud detection task. Here's why we made each choice:\n",
    "\n",
    "- **Dense layers with ReLU activation (`relu`)**:  \n",
    "  ReLU (Rectified Linear Unit) is the most common activation function for hidden layers because it helps the network learn complex, non-linear patterns while avoiding problems like vanishing gradients that occur with older functions (e.g., sigmoid, tanh). ReLU keeps training efficient and effective.  \n",
    "\n",
    "- **Output layer with sigmoid activation**:  \n",
    "  Since this is a binary classification problem (fraud vs. non-fraud), we use `sigmoid` to output probabilities between 0 and 1.  \n",
    "\n",
    "- **Loss function (`binary_crossentropy`)**:  \n",
    "  This is the standard loss for binary classification. It measures the difference between predicted probabilities and actual labels (fraud = 1, not fraud = 0). Minimizing this loss helps the model improve its probability predictions.  \n",
    "\n",
    "- **Optimizer (Adam, learning rate = 0.001)**:  \n",
    "  Adam is widely used because it adapts the learning rate for each parameter automatically, combining the strengths of momentum and RMSprop optimizers. The default learning rate of **0.001** is a good starting point—it’s small enough to ensure stable convergence but fast enough to make progress during training. If training is too slow or unstable, this value can be tuned.  \n",
    "\n",
    "- **Metrics (`accuracy`, `AUC`, `Precision`, `Recall`)**:  \n",
    "  - `accuracy` gives the overall correctness, but can be misleading with imbalanced datasets.  \n",
    "  - `AUC` (Area Under ROC Curve) measures the model’s ability to distinguish between fraud and non-fraud across thresholds.  \n",
    "  - `precision` tells us how many of the transactions predicted as fraud are truly fraud.  \n",
    "  - `recall` tells us how many of the actual frauds were correctly detected.  \n",
    "  These metrics provide a balanced view of performance beyond just accuracy, which is critical in fraud detection where fraud cases are rare.  \n",
    "\n",
    "  We also create a small dense network:\n",
    "- 32 → 16 neurons in hidden layers\n",
    "- Dropout 20% to reduce overfitting\n",
    "- Sigmoid output for binary classification\n",
    "- Use AUC as a metric for evaluation during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c3982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.5008661206149896, 1: 289.14340101522845}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights: inverse of class frequency\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e5c86",
   "metadata": {},
   "source": [
    "So, the calculated class weights show that fraud cases (1) are very rare compared to non-fraud cases (0).  \n",
    "To balance this, each fraud sample is weighted about 289 times more than a non-fraud sample, ensuring the model pays more attention to detecting fraud. This helps prevent the model from always predicting \"not fraud\" due to class imbalance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fba7a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 10:19:32.720097: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 43746240 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "90/90 [==============================] - 16s 10ms/step - loss: 1.0366 - auc: 0.5612 - val_loss: 0.5611 - val_auc: 0.8860\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4473 - auc: 0.8593 - val_loss: 0.4230 - val_auc: 0.9284\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3478 - auc: 0.9178 - val_loss: 0.3073 - val_auc: 0.9480\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2813 - auc: 0.9391 - val_loss: 0.2313 - val_auc: 0.9571\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2553 - auc: 0.9538 - val_loss: 0.1963 - val_auc: 0.9684\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2287 - auc: 0.9600 - val_loss: 0.1687 - val_auc: 0.9742\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2034 - auc: 0.9676 - val_loss: 0.1537 - val_auc: 0.9787\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1691 - auc: 0.9787 - val_loss: 0.1272 - val_auc: 0.9796\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1718 - auc: 0.9773 - val_loss: 0.1202 - val_auc: 0.9807\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1703 - auc: 0.9802 - val_loss: 0.1154 - val_auc: 0.9818\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,          # start small; increase if needed\n",
    "    batch_size=2048,    # large batch works for big dataset\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025ca20",
   "metadata": {},
   "source": [
    "The model shows strong improvement across epochs. Validation AUC started at **0.8860** in epoch 1 and climbed to **0.9818** by epoch 10, indicating excellent ability to separate fraud from non-fraud. Meanwhile, the validation loss steadily decreased, suggesting the model is learning effectively without overfitting yet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e832a51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 2s 1ms/step\n",
      "PR AUC: 0.6865493065868986\n",
      "ROC AUC: 0.9785571445798353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9774    0.9885     56864\n",
      "           1     0.0649    0.9082    0.1211        98\n",
      "\n",
      "    accuracy                         0.9773     56962\n",
      "   macro avg     0.5324    0.9428    0.5548     56962\n",
      "weighted avg     0.9982    0.9773    0.9870     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities\n",
    "y_prob = model.predict(X_test).flatten()\n",
    "y_pred_05 = (y_prob > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "print(\"PR AUC:\", average_precision_score(y_test, y_prob))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(classification_report(y_test, y_pred_05, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46f1d3",
   "metadata": {},
   "source": [
    "The model achieved an excellent **ROC AUC of 0.9786**, showing very strong overall discrimination between fraud and non-fraud cases. The **PR AUC of 0.687** is also solid, which is more meaningful for this imbalanced dataset since it focuses on fraud detection. Precision for fraud (class 1) is relatively low (**0.0649**), but recall is very high (**0.9082**), meaning the model successfully captures most fraud cases while producing more false positives. This tradeoff is typical in fraud detection and can be tuned further by adjusting the decision threshold.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e0bfcc6-4dc1-4750-9219-03b2b0aa7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_default = (y_prob > 0.3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "271b6e0c-8982-4d6a-bfac-75e1462705e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     56864\n",
      "           1       0.03      0.92      0.05        98\n",
      "\n",
      "    accuracy                           0.94     56962\n",
      "   macro avg       0.51      0.93      0.51     56962\n",
      "weighted avg       1.00      0.94      0.97     56962\n",
      "\n",
      "ROC AUC: 0.9785571445798353\n",
      "PR AUC: 0.6865493065868986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
    "\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"PR AUC:\", average_precision_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3da695b1-dd1a-44b9-98e1-5af2f657b4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        y_true    y_prob  y_pred\n",
      "260549       0  0.020424       0\n",
      "207920       0  0.022005       0\n",
      "9890         0  0.111868       0\n",
      "169108       0  0.009085       0\n",
      "240991       0  0.134147       0\n",
      "216605       0  0.016075       0\n",
      "170739       0  0.057379       0\n",
      "146712       0  0.028239       0\n",
      "270298       0  0.108854       0\n",
      "91976        0  0.184660       0\n",
      "109053       0  0.135872       0\n",
      "120232       0  0.068312       0\n",
      "240679       0  0.088868       0\n",
      "197111       0  0.043105       0\n",
      "258617       0  0.039338       0\n",
      "115271       0  0.118311       0\n",
      "10697        0  0.106195       0\n",
      "149485       0  0.019753       0\n",
      "4763         0  0.082657       0\n",
      "2407         0  0.013978       0\n",
      "186654       0  0.046306       0\n",
      "44808        0  0.164087       0\n",
      "40938        0  0.010531       0\n",
      "252178       0  0.021987       0\n",
      "79255        0  0.014979       0\n",
      "134085       0  0.173714       0\n",
      "188613       0  0.018134       0\n",
      "5777         0  0.072969       0\n",
      "146436       0  0.015231       0\n",
      "201670       0  0.065001       0\n",
      "210731       0  0.036123       0\n",
      "222756       0  0.221859       0\n",
      "178998       0  0.208958       0\n",
      "137165       0  0.102386       0\n",
      "39705        0  0.020299       0\n",
      "75296        0  0.056591       0\n",
      "114404       0  0.021693       0\n",
      "160994       0  0.011119       0\n",
      "110489       0  0.065637       0\n",
      "222742       0  0.010603       0\n",
      "275470       0  0.038508       0\n",
      "230411       0  0.345839       1\n",
      "152066       0  0.016584       0\n",
      "69555        0  0.017807       0\n",
      "156307       0  0.013456       0\n",
      "283893       0  0.042482       0\n",
      "248470       0  0.123845       0\n",
      "102259       0  0.133780       0\n",
      "257381       0  0.078026       0\n",
      "43279        0  0.216784       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine predictions and probabilities for a few samples\n",
    "results = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'y_prob': y_prob,\n",
    "    'y_pred': y_pred_default\n",
    "})\n",
    "print(results.sample(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
